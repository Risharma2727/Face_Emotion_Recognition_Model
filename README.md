# ðŸŽ­ Multimodal Emotion Recognition System (Facial + Audio)

This project implements a real-time emotion recognition system using both **facial expressions** and **audio signals**. It leverages deep learning models trained on standard datasets to detect emotions from webcam video and microphone input.

---

## ðŸ“¦ Datasets Used

### ðŸ§  Facial Emotion Dataset
- **Source**: [FER2013](https://www.kaggle.com/datasets/msambare/fer2013)
- **Classes**: Angry, Disgust, Fear, Happy, Neutral, Sad, Surprise
- **Format**: Grayscale images (48x48), organized by emotion folders

### ðŸŽ™ï¸ Audio Emotion Dataset
- **Source**: [RAVDESS](https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio)
- **Classes**: Neutral, Calm, Happy, Sad, Angry, Fearful, Disgust, Surprised
- **Format**: `.wav` files with emotion encoded in filename

---

## ðŸ§  Algorithms Used

- **Facial Emotion Recognition**: Convolutional Neural Network (CNN)
- **Audio Emotion Recognition**: CNN trained on MFCC features
- **Feature Extraction**:
  - Facial: Resized grayscale image â†’ normalized â†’ CNN input
  - Audio: MFCC + delta features â†’ mean pooled â†’ CNN input
- **Smoothing**: Rolling window (deque) for stable predictions
- **Confidence Filtering**: Only predictions above threshold are accepted

---

## ðŸ”„ Flow of Code Execution

1. **Load Models**: Facial and audio models are loaded from `.json` and `.h5` files
2. **Start Webcam**: Captures frames and detects faces using Haar cascade
3. **Face Prediction**:
   - Every few frames, face is cropped and passed to CNN
   - Emotion is predicted and smoothed over time
4. **Manual Audio Trigger**:
   - Press `'a'` to record 2 seconds of audio
   - MFCC features are extracted and passed to audio model
   - Emotion is predicted and smoothed
5. **Display Output**:
   - Webcam frame shows bounding box, facial emotion, and audio emotion
   - Press `'q'` to quit

---

## ðŸ–¼ï¸ Flow of Output

| Component        | Behavior                                                                |
|------------------|-------------------------------------------------------------------------|
| Webcam Feed      | Real-time video with face detection and emotion overlay                 |
| Facial Emotion   | Updated every 10 frames, smoothed for stability                         |
| Audio Emotion    | Triggered manually, displayed below webcam feed                         |
| Rectangle Flicker| Eliminated using face hold mechanism                                    |
| Prediction Delay | Minimized with optimized intervals and threading                        |

---

## ðŸŽ® Manual Controls

- Press `'a'` â†’ Record audio and predict emotion  
- Press `'q'` â†’ Quit the application cleanly

---

## ðŸ“Š Accuracy

| Model        | Accuracy (on full dataset) |
|--------------|----------------------------|
| Facial CNN   | ~96.09%â€“97.89% (FER2013)   |
| Audio CNN    | ~92â€“95.3% (RAVDESS)        |

> Accuracy can be improved with transfer learning, data augmentation, and balanced datasets.

---

## âœ… Results

- Real-time multimodal emotion detection with smooth UI
- Stable predictions using temporal smoothing
- Manual audio trigger for controlled evaluation
- Modular codebase for easy extension and retraining


---

## ðŸš€ Future Improvements

- Fuse face and audio predictions into a unified emotion output  
- Add real-time emotion dashboard or logging  
- Deploy as a desktop or web app  
- Use MobileNetV2 or EfficientNet for higher accuracy

---





